{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **World Model – Rollouts Generation**\n",
    "---\n",
    "\n",
    "**This notebook focuses on generating datasets consisting of environment observations (images) and actions to train the Vision Model (VAE) and Memory Model (LSTM-MDN) as part of the World Model framework.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Environment - CarRacing-v3**\n",
    "---\n",
    "The [CarRacing-v3](https://gymnasium.farama.org/environments/box2d/car_racing/)\n",
    "environment from Gymnasium provides a challenging reinforcement learning task where the agent must navigate a race track.\n",
    "\n",
    "<img src=\"imgs/CarRacing.gif\" alt=\"CarRacing Game\" width=\"500\" style=\"border-radius: 25px;\"/>\n",
    "\n",
    "#### **Environment Details**\n",
    "Each time the environment resets, a procedurally generated race track is created. The complexity varies significantly - from simple tracks with gentle curves to complex circuits with numerous tight 180° turns.\n",
    "\n",
    "**Continuous Action Space:**\n",
    "- Steering: [-1, 1] (negative: left, positive: right)\n",
    "- Acceleration: [0, 1] (higher values increase speed)\n",
    "- Braking: [0, 1] (higher values increase braking force)\n",
    "\n",
    "**Reward Structure:**\n",
    "Each episode lasts for 1000 time steps maximum\n",
    "A constant penalty of -0.1 is applied at each time step\n",
    "The track is divided into tiles; driving over a tile provides +1000/N reward (where N is the total number of tiles)\n",
    "For example, completing a track (passing over all tiles) in 732 steps would yield a total reward of: 1000 - (0.1 × 732) = 926.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Image Processing**\n",
    "---\n",
    "\n",
    "The **CarRacing-v3** environment provides observations with a resolution of ```(96×96×3)```. We'll maintain the resolution of ```(96×96×3)``` but crop the game information display from the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('CarRacing-v3', render_mode=\"rgb_array\")\n",
    "env.reset()\n",
    "for _ in range(70):\n",
    "    obs, reward, done, truncated, info = env.step(np.array([0,1,0]))\n",
    "\n",
    "obs_cropped = obs[:-12, :, :]\n",
    "obs_cropped = Image.fromarray(obs_cropped)\n",
    "obs_resized = obs_cropped.resize((96,96), Image.Resampling.LANCZOS)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].imshow(obs)\n",
    "axs[0].set_title('Enviroment observation (96x96)')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(obs_resized)\n",
    "axs[1].set_title('Cropped + Resized (96x96)')\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pseudo-Random Action Strategy**\n",
    "--- \n",
    "\n",
    "Using purely random actions creates a significant data collection issue. Random actions typically cause the car to spin out of control and drive off the track, resulting in an unbalanced dataset with few useful driving examples. This would lead to:\n",
    "\n",
    "- Poor reconstruction of crucial features like sharp turns\n",
    "- Inconsistent road distribution in the latent space\n",
    "- Insufficient examples for the model to learn proper driving behavior\n",
    "\n",
    "To address this, we use a pseudo-random action strategy with the following distribution:\n",
    "\n",
    "| Acción         | Valores               | Probabilidad     |\n",
    "|----------------|-----------------------|-------------------|\n",
    "| Accelerate    | [0, random, 0]       | 35%               |\n",
    "| Turn Left     | [-random, 0, 0]      | 30%               |\n",
    "| Turn Right\t| [+random, 0, 0]      | 30%               |\n",
    "| Brake         | [0, 0, random]       | 5%               |\n",
    "\n",
    "Where \"random\" is a value between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def random_action(t):\n",
    "    \"\"\"\n",
    "    Generate pseudo-random actions based on the current time step (t).\n",
    "    \n",
    "    Args:\n",
    "        t: Current time step in the episode\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Action vector [steering, acceleration, brake]\n",
    "    \"\"\"\n",
    "    if t < 20:\n",
    "        return np.array([-.1, 1, 0])\n",
    "\n",
    "    actions = [\n",
    "        np.array([0, np.random.random(), 0]),    # Random Accelerate\n",
    "        np.array([-np.random.random(), 0, 0]),   # Random Turn Left\n",
    "        np.array([np.random.random(), 0, 0]),    # Random Turn Right\n",
    "        np.array([0, 0, np.random.random()]),    # Random Brake\n",
    "    ]\n",
    "    probabilities = [.35, .3, .3, .05]  # Probabilities for each action\n",
    "\n",
    "    # Select a random action based on the defined probabilities\n",
    "    selected_action = np.random.choice(len(actions), p=probabilities)\n",
    "    return actions[selected_action]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Efficient Data Collection and Storage**\n",
    "---\n",
    "\n",
    "To optimize the process of generating a large dataset (e.g., 10.000 episodes), we utilize [HDF5](https://docs.h5py.org/en/stable/) for efficient data storage and parallel processing for data collection.\n",
    "\n",
    "### Data Collection Strategy\n",
    "\n",
    "1. **Parallelization**: The workload is distributed across available CPU cores, with each worker handling a portion of the episodes.\n",
    "2. **Intermediate Storage**: Each worker generates episodes and stores them in temporary HDF5 files.\n",
    "3. **Dataset Consolidation**: After all episodes are generated, the temporary files are merged into a single HDF5 dataset.\n",
    "4. **Episode Handling**: If the car goes off-track before completing the 1000 steps, the environment is reset and the episode continues until the full length is reached.\n",
    "\n",
    "### Final Dataset Structure\n",
    "\n",
    "```\n",
    "root:\n",
    "  actions = float32(num_episodes x 1000 x 3)\n",
    "  dones   =    bool(num_episodes x 1000)\n",
    "  images  =   uint8(num_episodes x 1000 x 96 x 96 x 3)\n",
    "  rewards = float32(num_episodes x 1000)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import h5py\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from PIL import Image\n",
    "import gc \n",
    "import os\n",
    "\n",
    "def resize_obs(image, target_size=(96, 96)):\n",
    "    \"\"\"\n",
    "    Crop the observation image and resize it to target_size.\n",
    "    \n",
    "    Args:\n",
    "        image: Raw observation image from environment\n",
    "        target_size: Desired output dimensions as (width, height)\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Processed image\n",
    "    \"\"\"\n",
    "    image_cropped = image[:-12, :, :]  # Remove bottom info bar\n",
    "    img = Image.fromarray(image_cropped)\n",
    "    img = img.resize(target_size, Image.Resampling.LANCZOS)  # High-quality downsampling\n",
    "    return np.array(img)\n",
    "\n",
    "\n",
    "def collect_episode(env_name, max_steps, episode_id, worker_id, output_dir):\n",
    "    \"\"\"\n",
    "    Collect data for a single episode and write it to an HDF5 file.\n",
    "    \n",
    "    Args:\n",
    "        env_name (str): The Gym environment identifier\n",
    "        max_steps (int): Maximum number of steps per episode\n",
    "        episode_id (int): The episode's unique identifier\n",
    "        worker_id (int): The worker's unique identifier\n",
    "        output_dir (str): Directory to store episode files\n",
    "    \"\"\"\n",
    "    # Initialize lists to store episode data\n",
    "    episode_images = []\n",
    "    episode_actions = []\n",
    "    episode_rewards = []\n",
    "    episode_dones = []\n",
    "    \n",
    "    env = gym.make(env_name, render_mode='rgb_array')\n",
    "    obs, _ = env.reset()\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        # Process and store the observation\n",
    "        resized_image = resize_obs(obs)\n",
    "        episode_images.append(resized_image)\n",
    "\n",
    "        # Generate action (new pseudo-random action every 20 steps)\n",
    "        if step % 20 == 0:\n",
    "            action = random_action(step)\n",
    "        episode_actions.append(action)\n",
    "\n",
    "        # Execute action and store results\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        episode_rewards.append(reward)\n",
    "        episode_dones.append(done)\n",
    "\n",
    "        # Reset if episode terminates early\n",
    "        if done:\n",
    "            obs, _ = env.reset()\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    episode_images = np.array(episode_images, dtype=np.uint8)\n",
    "    episode_actions = np.array(episode_actions, dtype=np.float32)\n",
    "    episode_rewards = np.array(episode_rewards, dtype=np.float32)\n",
    "    episode_dones = np.array(episode_dones, dtype=bool)\n",
    "\n",
    "    # Define the episode file path\n",
    "    episode_filename = f'worker_{worker_id}_episode_{episode_id}.h5'\n",
    "    episode_path = os.path.join(output_dir, episode_filename)\n",
    "\n",
    "    # Write the episode data to an HDF5 file\n",
    "    with h5py.File(episode_path, 'w') as h5f:\n",
    "        h5f.create_dataset('images', data=episode_images, dtype='uint8')\n",
    "        h5f.create_dataset('actions', data=episode_actions, dtype='float32')\n",
    "        h5f.create_dataset('rewards', data=episode_rewards, dtype='float32')\n",
    "        h5f.create_dataset('dones', data=episode_dones, dtype='bool')\n",
    "\n",
    "    # Clean up memory\n",
    "    env.close()\n",
    "    del episode_images, episode_actions, episode_rewards, episode_dones\n",
    "    del resized_image, action, reward, done, truncated, info, obs, env\n",
    "    gc.collect()  # Explicitly trigger garbage collection\n",
    "    \n",
    "\n",
    "def collect_data_worker(args):\n",
    "    \"\"\"\n",
    "    Worker function to collect multiple episodes and write each to a separate file.\n",
    "    \n",
    "    Args:\n",
    "        args: Tuple containing (env_name, num_episodes, max_steps, output_dir, worker_id)\n",
    "    \"\"\"\n",
    "    env_name, num_episodes, max_steps, output_dir, worker_id = args\n",
    "\n",
    "    for ep in range(num_episodes):\n",
    "        collect_episode(env_name, max_steps, ep, worker_id, output_dir)\n",
    "        print(f\"Worker {worker_id}: Episode ({ep+1}/{num_episodes}) completed\")\n",
    "\n",
    "    print(f\"Worker {worker_id}: Completed {num_episodes} episodes.\")\n",
    "\n",
    "\n",
    "def collect_data(env_name='CarRacing-v3', num_episodes=100, max_steps=1000, \n",
    "                output_dir='episodes_data', num_workers=None):\n",
    "    \"\"\"\n",
    "    Collect data from the environment and store each episode in a separate HDF5 file.\n",
    "    \n",
    "    Args:\n",
    "        env_name (str): Name of the Gym environment\n",
    "        num_episodes (int): Total number of episodes to generate\n",
    "        max_steps (int): Maximum steps per episode\n",
    "        output_dir (str): Directory to store episode files\n",
    "        num_workers (int, optional): Number of worker processes. Defaults to CPU count\n",
    "    \"\"\"\n",
    "    if num_workers is None:\n",
    "        num_workers = cpu_count()-1 # Use all available CPU cores\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Determine episodes per worker\n",
    "    episodes_per_worker = num_episodes // num_workers\n",
    "    remaining_episodes = num_episodes % num_workers\n",
    "\n",
    "    # Prepare arguments for each worker\n",
    "    worker_args = []\n",
    "    for i in range(num_workers):\n",
    "        worker_episodes = episodes_per_worker + (1 if i < remaining_episodes else 0)\n",
    "        args = (env_name, worker_episodes, max_steps, output_dir, i)\n",
    "        worker_args.append(args)\n",
    "\n",
    "    # Use Pool for multiprocessing with controlled number of workers\n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        list(pool.imap_unordered(collect_data_worker, worker_args))\n",
    "\n",
    "    print(\"Data collection completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "collect_data(env_name='CarRacing-v3', num_episodes=128, max_steps=1000, output_dir='temp_episodes_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Consolidating Episodes into a Single Dataset**\n",
    "After collecting individual episode data files, we need to merge them into a unified dataset structure for efficient training access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "def merge_episode_files(episodes_dir='temp_episodes_data',\n",
    "                        output_file='merged_data.h5', \n",
    "                        env_name='CarRacing-v3',\n",
    "                        num_max_steps=1000):\n",
    "    \"\"\"\n",
    "    Merge multiple episode HDF5 files into a single HDF5 dataset.\n",
    "    \n",
    "    Args:\n",
    "        episodes_dir (str): Directory containing individual episode files\n",
    "        output_file (str): Path for the consolidated output file\n",
    "        env_name (str): Environment name (for documentation purposes)\n",
    "        num_max_steps (int): Expected number of steps per episode\n",
    "    \"\"\"\n",
    "    # Step 1: Locate all episode files\n",
    "    episode_files = [\n",
    "        os.path.join(episodes_dir, f)\n",
    "        for f in os.listdir(episodes_dir)\n",
    "        if f.endswith('.h5') or f.endswith('.hdf5')\n",
    "    ]\n",
    "\n",
    "    num_episodes = len(episode_files)\n",
    "    if num_episodes == 0:\n",
    "        raise ValueError(f\"No HDF5 episode files found in directory: {episodes_dir}\")\n",
    "\n",
    "    print(f\"Found {num_episodes} episode files in '{episodes_dir}'.\")\n",
    "\n",
    "    # Optional: Sort files for consistent ordering\n",
    "    episode_files.sort()\n",
    "\n",
    "    # Step 2: Verify episode integrity\n",
    "    for file in episode_files:\n",
    "        with h5py.File(file, 'r') as h5f:\n",
    "            actions_shape = h5f['actions'].shape\n",
    "            if actions_shape[0] != num_max_steps:\n",
    "                raise ValueError(\n",
    "                    f\"Episode file {file} has {actions_shape[0]} steps, expected {num_max_steps}.\"\n",
    "                )\n",
    "\n",
    "    # Step 3: Initialize the merged HDF5 file\n",
    "    with h5py.File(output_file, 'w') as merged_h5f:\n",
    "        # Initialize datasets with optimized chunking\n",
    "        actions_shape = (num_episodes, num_max_steps, 3)\n",
    "        dones_shape = (num_episodes, num_max_steps)\n",
    "        images_shape = (num_episodes, num_max_steps, 96, 96, 3)\n",
    "        rewards_shape = (num_episodes, num_max_steps)\n",
    "\n",
    "        print(\"Initializing datasets in the merged HDF5 file...\")\n",
    "        merged_h5f.create_dataset('actions', shape=actions_shape,\n",
    "                                 dtype='float16', chunks=(1, num_max_steps, 3))\n",
    "        merged_h5f.create_dataset('dones', shape=dones_shape,\n",
    "                                 dtype='bool', chunks=(1, num_max_steps))\n",
    "        merged_h5f.create_dataset('images', shape=images_shape,\n",
    "                                 dtype='uint8', chunks=(1, num_max_steps, 96, 96, 3))\n",
    "        merged_h5f.create_dataset('rewards', shape=rewards_shape,\n",
    "                                 dtype='int', chunks=(1, num_max_steps))\n",
    "\n",
    "        # Step 4: Iterate through each episode and write to the merged file\n",
    "        for idx, episode_file in enumerate(tqdm(episode_files, desc=\"Merging Episodes\")):\n",
    "            with h5py.File(episode_file, 'r') as ep_h5f:\n",
    "                # Read datasets from the episode file\n",
    "                actions = ep_h5f['actions'][:]\n",
    "                dones = ep_h5f['dones'][:]\n",
    "                images = ep_h5f['images'][:]\n",
    "                rewards = ep_h5f['rewards'][:]\n",
    "\n",
    "                # Write to the merged datasets\n",
    "                merged_h5f['actions'][idx, :, :] = actions\n",
    "                merged_h5f['dones'][idx, :] = dones\n",
    "                merged_h5f['images'][idx, :, :, :, :] = images\n",
    "                merged_h5f['rewards'][idx, :] = rewards\n",
    "\n",
    "            # Step 5: Clean up temporary files\n",
    "            try:\n",
    "                os.remove(episode_file)\n",
    "            except Exception as de:\n",
    "                print(f\"Error deleting temporary file '{episode_file}': {de}\")\n",
    "\n",
    "    print(f\"Merging completed successfully. Merged data saved to '{output_file}'.\")\n",
    "\n",
    "\n",
    "# Merge the previously generated episode files\n",
    "merge_episode_files(episodes_dir='temp_episodes_data', \n",
    "                   output_file='car_racing_data_128.h5', \n",
    "                   env_name='CarRacing-v3', \n",
    "                   num_max_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nexusformat.nexus as nx\n",
    "\n",
    "# Verify dataset structure\n",
    "f = nx.nxload('car_racing_data_128.h5')\n",
    "print(f.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating a PyTorch Dataset**\n",
    "To efficiently use our collected data for model training, we'll implement a custom PyTorch Dataset that provides streaming access to the HDF5 file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class CarRacingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for CarRacing data stored in HDF5 format.\n",
    "    \n",
    "    This dataset provides on-demand access to observations, actions, rewards,\n",
    "    and done flags stored in the consolidated HDF5 file.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, h5_path='car_racing_data.h5', transform=None):\n",
    "        \"\"\"\n",
    "        Initialize the dataset.\n",
    "        \n",
    "        Args:\n",
    "            h5_path (str): Path to the HDF5 file containing the dataset\n",
    "            transform (callable, optional): Transform to apply to the observations\n",
    "        \"\"\"\n",
    "        self.h5_path = h5_path\n",
    "        \n",
    "        self.transform = transform if transform is not None else transforms.ToTensor()\n",
    "        \n",
    "        # Open the HDF5 file to retrieve dataset dimensions\n",
    "        with h5py.File(self.h5_path, 'r') as h5f:\n",
    "            self.num_episodes, self.max_steps = h5f['images'].shape[:2]\n",
    "            self.total_frames = self.num_episodes * self.max_steps\n",
    "    \n",
    "        self.h5_file = None  # Will be opened on first access\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of frames in the dataset.\"\"\"\n",
    "        return self.total_frames\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieve a single frame and associated data.\n",
    "        \n",
    "        Args:\n",
    "            idx (int): Index of the frame to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (image, action, reward, done) tensors\n",
    "        \"\"\"\n",
    "        if self.h5_file is None:\n",
    "            self.h5_file = h5py.File(self.h5_path, 'r')\n",
    "        \n",
    "        # Calculate episode and step from the flat index\n",
    "        episode = idx // self.max_steps\n",
    "        step = idx % self.max_steps\n",
    "        \n",
    "        # Access the datasets directly using episode and step indices\n",
    "        image = self.h5_file['images'][episode, step]       \n",
    "        action = self.h5_file['actions'][episode, step]      \n",
    "        reward = self.h5_file['rewards'][episode, step]     \n",
    "        done = self.h5_file['dones'][episode, step]          \n",
    "        \n",
    "        # Apply the transform (e.g., ToTensor)\n",
    "        image = self.transform(image)  # Converts to [C, H, W] and scales to [0, 1]\n",
    "        \n",
    "        # Convert action, reward, and done to tensors\n",
    "        action = torch.tensor(action, dtype=torch.float32)  \n",
    "        reward = torch.tensor(reward, dtype=torch.float32)  \n",
    "        done = torch.tensor(done, dtype=torch.float32)     \n",
    "        \n",
    "        return image, action, reward, done\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"Ensure the HDF5 file is closed when the dataset is deleted.\"\"\"\n",
    "        if self.h5_file is not None:\n",
    "            self.h5_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualizing the Dataset**\n",
    "\n",
    "This allows us to inspect the images in sequence, ensuring they're properly stored and aligned with their respective episode and step information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "def display_dataset(dataloader, scale=1):\n",
    "    \"\"\"\n",
    "    Visualize the dataset using Pygame.\n",
    "    \n",
    "    Args:\n",
    "        dataloader: PyTorch DataLoader containing the dataset\n",
    "        scale (int): Scale factor for display window\n",
    "    \"\"\"\n",
    "    pygame.init()\n",
    "    pygame.font.init()\n",
    "\n",
    "    # Configure pygame window\n",
    "    image_size = 96\n",
    "    window_size = (int(image_size * scale), int(image_size * scale))\n",
    "    screen = pygame.display.set_mode(window_size)\n",
    "    pygame.display.set_caption('Dataset Visualizer')\n",
    "    clock = pygame.time.Clock()  \n",
    "\n",
    "    rollout_id = 0\n",
    "    step = 0\n",
    "\n",
    "    for images, actions, rewards, dones in dataloader:\n",
    "        # Process the image for display\n",
    "        images = images.squeeze(0).permute(2, 1, 0).cpu().numpy()  \n",
    "        images = (images * 255).astype(np.uint8)  \n",
    "        images = pygame.surfarray.make_surface(images)\n",
    "        images = pygame.transform.scale(images, window_size)  \n",
    "\n",
    "        # Draw the image to screen\n",
    "        screen.blit(images, (0, 0))\n",
    "\n",
    "        # Add rollout and step information overlay\n",
    "        font = pygame.font.SysFont(None, 24)\n",
    "        text = font.render(f'Rollout: {rollout_id} Step: {step}', True, (255, 255, 255))\n",
    "        screen.blit(text, (10, 10))\n",
    "\n",
    "        pygame.display.update()\n",
    "\n",
    "        # Control playback speed\n",
    "        clock.tick(60)  # 60 FPS\n",
    "        \n",
    "        # Update step/episode counters\n",
    "        step += 1\n",
    "        if step == 1000:  # End of episode\n",
    "            step = 0\n",
    "            rollout_id += 1\n",
    "\n",
    "        # Check for exit command\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                return\n",
    "\n",
    "    pygame.quit()\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = CarRacingDataset('car_racing_data_128.h5')\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Launch the visualizer\n",
    "display_dataset(dataloader, scale=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
